{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Diabetes in Women of the Pima Indigenous People"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction: \n",
    "\n",
    "Predict whether a woman in the Pima Tribe will be diagnosed with diabetes in the next 5 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Info : \n",
    "\n",
    "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Attributes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregnancies:  Number of times pregnant\n",
    "\n",
    "Glucose:  Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "\n",
    "BloodPressure:  Diastolic blood pressure (mm Hg) \n",
    "\n",
    "SkinThickness:  Triceps skin fold thickness (mm) \n",
    "\n",
    "Insulin:  2-Hour serum insulin (mu U/ml) \n",
    "\n",
    "BMI:  Body mass index (weight in kg/(height in m)^2) \n",
    "\n",
    "DiabetesPedigreeFunction:  measure of genetic influence and hereditary risk \n",
    "\n",
    "Age:  Age (years) \n",
    "\n",
    "Outcome:  Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks \n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING\n",
    "\n",
    "(cleaning steps were moved into a function in the EDA section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'diabetes.csv' does not exist: b'diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bd32d810057f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'diabetes.csv' does not exist: b'diabetes.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Pregnancies.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pregnancies'] >= 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()  #min 0 must be missing data for vitals/blood columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.pregnancies.value_counts()  #bin these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.SkinThickness.value_counts() # 227 missing values for skin thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.BMI.value_counts() #only 11 missing values for BMI, will replace with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.BMI.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Insulin.value_counts() # 374 missing values for insulin level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Insulin.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.BloodPressure.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & FEATURE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('darkgrid',{'axes.edgecolor': '.6'})\n",
    "# sns.pairplot(df, hue='Outcome', palette='husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "targ = df1['Outcome']\n",
    "feat = df1.drop('Outcome', axis=1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(feat, targ, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain, ytrain)\n",
    "pred_trn = logreg.predict(Xtrain)\n",
    "print('TRAINING F1: ', metrics.f1_score(ytrain, pred_trn))\n",
    "print(confusion_matrix(ytrain,pred_trn))\n",
    "\n",
    "pred_tst = logreg.predict(Xtest)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest, pred_tst))\n",
    "print(confusion_matrix(ytest,pred_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',{'axes.edgecolor': '.9'})\n",
    "sns.jointplot(df.Insulin, df.Glucose, color='lightseagreen') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',{'axes.edgecolor': '.9'})\n",
    "sns.jointplot(df.BMI, df.SkinThickness, color='violet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy.BMI = df_copy.BMI.replace({0:32})\n",
    "bins = [10,20,30,40,50,60]\n",
    "bins_bmi = pd.cut(df_copy['BMI'], bins)\n",
    "bins_bmi = bins_bmi.cat.as_unordered()\n",
    "df_copy['BinBMI'] = bins_bmi\n",
    "df_copy.groupby(['BinBMI']).SkinThickness.mean()\n",
    "\n",
    "#replacing zeros with the average per BMI group, this is added to the data cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shape(df):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    df = df.rename({'diabetespedigreefunction': 'dpf', 'outcome':'diabetes'}, axis=1)\n",
    "    df = df[df['insulin'] < 600] #drop outliers\n",
    "    df = df[df['skinthickness'] < 70] #drop outliers\n",
    "    df = df[df['bmi'] < 55] #drop outliers\n",
    "    df = df[df['glucose'] > 0] #drop zeros\n",
    "    df.bloodpressure = df.bloodpressure.replace({0:72}) #replace zeros with mean\n",
    "    df.insulin = df.insulin.replace({0:30.5})\n",
    "    df.bmi = df.bmi.replace({0:32}) #replace zeros with mean\n",
    "    \n",
    "    #replace skin thickness with mean of thickness by bmi group\n",
    "    \n",
    "    mask1 = (df['skinthickness'] == 0) & (df['bmi'] <= 20)\n",
    "    col1 = 'skinthickness'\n",
    "    df.loc[mask1, col1] = 9.64\n",
    "\n",
    "    mask2 = (df['skinthickness'] == 0) & (df['bmi'] <= 30)\n",
    "    col2 = 'skinthickness'\n",
    "    df.loc[mask2, col2] = 14.36\n",
    "\n",
    "    mask3 = (df['skinthickness'] == 0) & (df['bmi'] <= 40)\n",
    "    col3 = 'skinthickness'\n",
    "    df.loc[mask3, col3] = 23.37\n",
    "\n",
    "    mask4 = (df['skinthickness'] == 0) & (df['bmi'] <= 50)\n",
    "    col4 = 'skinthickness'\n",
    "    df.loc[mask4, col4] = 28.26\n",
    "\n",
    "    mask5 = (df['skinthickness'] == 0) & (df['bmi'] <= 60)\n",
    "    col5 = 'skinthickness'\n",
    "    df.loc[mask5, col5] = 32.71\n",
    "    \n",
    "    #CAUTION: this is also executed below\n",
    "    \n",
    "#     df['healthy_bmi'] = df.bmi.apply([lambda x: 1 if (x <= 24.9) & (x >= 18.5) else 0])\n",
    "#     df['healthy_bp'] = df.bloodpressure.apply([lambda x: 1 if x <= 120 else 0])\n",
    "#     df['healthy_glu'] = df.glucose.apply([lambda x: 1 if x <= 110 else 0])\n",
    "#     df['healthy_ins'] = df.insulin.apply([lambda x: 1 if x <= 100 else 0])    \n",
    "#     df['healthy_preg'] = df.pregnancies.apply([lambda x: 1 if x < 5 else 0])\n",
    "#     df['healthy_dpf'] = df.dpf.apply([lambda x: 1 if x <= 0.4259 else 0])\n",
    "#     df['health_score'] = df.healthy_preg + df.healthy_ins + df.healthy_glu + df.healthy_bp + df.healthy_dpf + df.healthy_bmi    \n",
    "#      df['dpf_log']= np.log(df.dpf)\n",
    "# # df.drop(columns=['dpf'], inplace=True)\n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df = df.copy() #for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = df.drop('diabetes', axis = 1)\n",
    "b = df['diabetes'] \n",
    "feature_cols = A.columns\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(b, alpha =.50, palette= ['tomato','c'], edgecolor='gray')\n",
    "plt.title('Diabetes vs No Diabetes')\n",
    "plt.ylabel('# of Women')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',{'axes.edgecolor': '.9'},)\n",
    "f, ax = plt.subplots(3,3,figsize = (20,16))\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "\n",
    "vis1 = sns.distplot(df[\"pregnancies\"],bins=10, color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=2),ax= ax[0][0])\n",
    "vis2 = sns.distplot(df[\"glucose\"],bins=10, color ='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[0][1])\n",
    "vis3 = sns.distplot(df[\"bloodpressure\"],bins=10, color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[0][2])\n",
    "vis4 = sns.distplot(df[\"skinthickness\"],bins=10,color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[1][0])\n",
    "vis5 = sns.distplot(df[\"insulin\"],bins=10,color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[1][1])\n",
    "vis6 = sns.distplot(df[\"bmi\"],bins=10,color='tomato', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[1][2])\n",
    "vis7 = sns.distplot(df[\"dpf\"],bins=10, color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[2][0])\n",
    "vis8 = sns.distplot(df[\"age\"],bins=10,color='tomato', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[2][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df['insulin_log'] = np.log(log_df.insulin)\n",
    "log_df['dpf_log']= np.log(log_df.dpf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',{'axes.edgecolor': '.9'},)\n",
    "f, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "\n",
    "v1 = sns.distplot(log_df[\"insulin_log\"],bins=10,color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[0])\n",
    "v2 = sns.distplot(log_df[\"dpf_log\"],bins=10, color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.drop(columns=['insulin','dpf'], inplace=True) #logging insulin did not improve the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, min_k=None, max_k=None):\n",
    "    best_k = 0\n",
    "    best_score = 0.0\n",
    "    for k in range(min_k, max_k+1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        preds = knn.predict(X_test)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        if f1 > best_score:\n",
    "            best_k = k\n",
    "            best_score = f1\n",
    "            \n",
    "    \n",
    "    print(\"Best Value for k: {}\".format(best_k))\n",
    "    print(\"F1-Score: {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model 1 : Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_target = log_df['diabetes']\n",
    "l_features = log_df.drop('diabetes', axis=1)\n",
    "Xtrain_l, Xtest_l, ytrain_l, ytest_l = train_test_split(l_features, l_target, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_lg = StandardScaler()\n",
    "scalar_lg.fit(Xtrain_l)\n",
    "Xtrain_l_scaled  = scalar_lg.transform(Xtrain_l)\n",
    "Xtest_l_scaled = scalar_lg.transform(Xtest_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain_l, ytrain_l)\n",
    "predl_tr = logreg.predict(Xtrain_l)\n",
    "print('TRAINING F1: ', metrics.f1_score(predl_tr, ytrain_l))\n",
    "print(confusion_matrix(predl_tr, ytrain_l))\n",
    "\n",
    "predl_tst = logreg.predict(Xtest_l)\n",
    "print('TESTING F1: ', metrics.f1_score(predl_tst, ytest_l))\n",
    "print(confusion_matrix(predl_tst,ytest_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin two variables to test whether this will increase our f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(feat_df.pregnancies, bins=30, color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1, 0, 1, 3, 5, 8, 17]\n",
    "preg_bs = pd.cut(feat_df['pregnancies'], bins)\n",
    "preg_bs = preg_bs.cat.as_unordered()\n",
    "preg_bins = pd.get_dummies(preg_bs, prefix=\"preg\")\n",
    "feat_df = feat_df.drop(columns=['pregnancies'])\n",
    "feat_df = pd.concat([feat_df, preg_bins],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bin_dist = feat_df.groupby([preg_bs]).size()\n",
    "bin_dist.plot(kind='barh',color='violet',edgecolor='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(feat_df.age, bins=30, color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [21, 23, 26, 30, 38, 46, 80]\n",
    "age_bs = pd.cut(feat_df['age'], bins)\n",
    "age_bs = age_bs.cat.as_unordered()\n",
    "age_bins = pd.get_dummies(age_bs, prefix=\"age\")\n",
    "feat_df = feat_df.drop(columns=['age'])\n",
    "feat_df = pd.concat([feat_df, age_bins],axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin_dist = feat_df.groupby([age_bs]).size()\n",
    "bin_dist.plot(kind='barh',color='c',edgecolor='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model 2 : Binned & Logged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = feat_df.copy()\n",
    "targ2 = df2['diabetes']\n",
    "feat2 = df2.drop('diabetes', axis=1)\n",
    "Xtrain2, Xtest2, ytrain2, ytest2 = train_test_split(feat2, targ2, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_lg = StandardScaler()\n",
    "scalar_lg.fit(Xtrain2)\n",
    "Xtrain2_scaled  = scalar_lg.transform(Xtrain2)\n",
    "Xtest2_scaled = scalar_lg.transform(Xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain2, ytrain2)\n",
    "pred2_tr = logreg.predict(Xtrain2)\n",
    "print('TRAINING F1: ', metrics.f1_score(pred2_tr, ytrain2))\n",
    "print(confusion_matrix(pred2_tr, ytrain2))\n",
    "\n",
    "pred2 = logreg.predict(Xtest2)\n",
    "print('TESTING F1: ', metrics.f1_score(pred2, ytest2))\n",
    "print(confusion_matrix(pred2,ytest2))\n",
    "\n",
    "#this did not perform better than the unbinned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split on the data without logging\n",
    "p_target = poly_df['diabetes']\n",
    "p_features = poly_df.drop('diabetes', axis=1)\n",
    "pXtrain, pXtest, pytrain, pytest = train_test_split(p_features, p_target, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_2 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly_2.fit(pXtrain)\n",
    "X_train_2= pd.DataFrame(poly_2.transform(pXtrain), columns = poly_2.get_feature_names(p_features.columns))\n",
    "X_test_2= pd.DataFrame(poly_2.transform(pXtest), columns = poly_2.get_feature_names(p_features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model 3 : Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_2 = StandardScaler()\n",
    "scalar_2.fit(X_train_2)\n",
    "X_train_2_scaled  = scalar_2.transform(X_train_2)\n",
    "X_test_2_scaled = scalar_2.transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_2_scaled, pytrain)\n",
    "y_train_2_pred = logreg.predict(X_train_2_scaled)\n",
    "print('TRAINING F1: ', metrics.f1_score(pytrain, y_train_2_pred))\n",
    "print(confusion_matrix(pytrain, y_train_2_pred))\n",
    "\n",
    "y_test_2_pred = logreg.predict(X_test_2_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(pytest, y_test_2_pred))\n",
    "print(confusion_matrix(pytest, y_test_2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k(X_train_2_scaled, pytrain, X_test_2_scaled, pytest,min_k=1, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so far this is the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine who has healthy BMI 18.5 to 24.9, bloodpressure <=120, glucose <=110, insulin < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['healthy_bmi'] = df.bmi.apply([lambda x: 1 if (x <= 24.9) & (x >= 18.5) else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['healthy_bp'] = df.bloodpressure.apply([lambda x: 1 if x <= 120 else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['healthy_glu'] = df.glucose.apply([lambda x: 1 if x <= 110 else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['healthy_ins'] = df.insulin.apply([lambda x: 1 if x <= 100 else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Diabetic DPF: ',df[df['diabetes'] == 1].dpf.mean())\n",
    "print('Undiabetic DPF: ',df[df['diabetes'] == 0].dpf.mean())\n",
    "\n",
    "#the difference is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['healthy_dpf'] = df.dpf.apply([lambda x: 1 if x <= 0.4259 else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pregnancy paper https://www.ncbi.nlm.nih.gov/pubmed/12177894\n",
    "#complications increase after pregnancy 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['healthy_preg'] = df.pregnancies.apply([lambda x: 1 if x < 5 else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['health_score'] = df.healthy_preg + df.healthy_ins + df.healthy_glu + df.healthy_bp + df.healthy_dpf + df.healthy_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df4.corr()\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df4.health_score, bins=30, color='tomato',hist_kws=dict(edgecolor=\"k\", linewidth=.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log dpf\n",
    "\n",
    "df4['dpf_log']= np.log(df4.dpf)\n",
    "df4.drop(columns=['dpf'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "target4 = df4['diabetes']\n",
    "features4 = df4.drop('diabetes', axis=1)\n",
    "Xtrain4, Xtest4, ytrain4, ytest4 = train_test_split(features4, target4, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model 4 : Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the features\n",
    "scalar4 = StandardScaler()\n",
    "scalar4.fit(Xtrain4)\n",
    "Xtrain4_scaled  = scalar4.transform(Xtrain4)\n",
    "Xtest4_scaled = scalar4.transform(Xtest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain4_scaled, ytrain4)\n",
    "ytrain4_pred = logreg.predict(Xtrain4_scaled)\n",
    "print('TRAINING F1: ', metrics.f1_score(ytrain4, ytrain4_pred))\n",
    "print(confusion_matrix(ytrain4, ytrain4_pred))\n",
    "\n",
    "ytest4_pred = logreg.predict(Xtest4_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, ytest4_pred))\n",
    "print(confusion_matrix(ytest4, ytest4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_4 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_4.fit(Xtrain4)\n",
    "X_train_4= pd.DataFrame(poly_4.transform(Xtrain4), columns = poly_4.get_feature_names(features4.columns))\n",
    "X_test_4= pd.DataFrame(poly_4.transform(Xtest4), columns = poly_4.get_feature_names(features4.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model 5 : Polynomial Features  + Feature Eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_4 = StandardScaler()\n",
    "scalar_4.fit(X_train_4)\n",
    "X_train_4_scaled  = scalar_4.transform(X_train_4)\n",
    "X_test_4_scaled = scalar_4.transform(X_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_4_scaled, ytrain4)\n",
    "y_train_4_pred = logreg.predict(X_train_4_scaled)\n",
    "print('TRAINING F1: ', metrics.f1_score(ytrain4, y_train_4_pred))\n",
    "print(confusion_matrix(ytrain4, y_train_4_pred))\n",
    "\n",
    "y_test_4_pred = logreg.predict(X_test_4_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, y_test_4_pred))\n",
    "print(confusion_matrix(ytest4, y_test_4_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, min_k=None, max_k=None):\n",
    "    best_k = 0\n",
    "    best_score = 0.0\n",
    "    for k in range(min_k, max_k+1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        preds = knn.predict(X_test)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        if f1 > best_score:\n",
    "            best_k = k\n",
    "            best_score = f1\n",
    "            \n",
    "    \n",
    "    print(\"Best Value for k: {}\".format(best_k))\n",
    "    print(\"F1-Score: {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    print('Training R^2 :',model.score(X_train,y_train))\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Training Root Mean Square Error',np.sqrt(metrics.mean_squared_error(y_train,y_pred_train)))\n",
    "    print('\\n----------------\\n')\n",
    "    print('Testing R^2 :',model.score(X_test,y_test))\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print('Testing Root Mean Square Error',np.sqrt(metrics.mean_squared_error(y_test,y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train_4_scaled, ytrain4)\n",
    "run_model(log,X_train_4_scaled, X_test_4_scaled, ytrain4, ytest4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(max_iter=100,cv=5)\n",
    "lasso.fit(X_train_4_scaled, ytrain4)\n",
    "run_model(lasso ,X_train_4_scaled, X_test_4_scaled, ytrain4, ytest4)\n",
    "print(\"The optimal alpha for the Lasso Regression is: \",lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "\n",
    "print(\"Number of coefs: \", len(lasso.coef_))\n",
    "print(\"Number at 0: \", sum(abs(lasso.coef_) < 10**(-10)))\n",
    "print(\"Number of coef used: \",coeff_used)\n",
    "print(\"Percent reduced: \", sum(abs(lasso.coef_) < 10**(-10))/135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4.columns[(lasso.coef_ != 0).tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pregnancies glucose', 'pregnancies insulin', 'glucose^2',\n",
    "       'glucose bloodpressure', 'glucose insulin', 'glucose bmi',\n",
    "       'bloodpressure^2', 'bloodpressure age', 'skinthickness^2',\n",
    "       'skinthickness insulin', 'insulin^2', 'insulin bmi', 'insulin age',\n",
    "       'bmi age', 'age^2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using original df4 train test split that is not yet scaled\n",
    "X_train_5 = X_train_4[cols]\n",
    "X_test_5 = X_test_4[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_5 = StandardScaler()\n",
    "scaler_5.fit(X_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_5_scaled = pd.DataFrame(scaler_5.transform(X_train_5),columns=X_train_5.columns)\n",
    "X_test_5_scaled = pd.DataFrame(scaler_5.transform(X_test_5), columns = X_train_5.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graphing remaining features\n",
    "\n",
    "sns.set_style('darkgrid',{'axes.edgecolor': '.9'},)\n",
    "f, ax = plt.subplots(5,3,figsize = (30,30))\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "\n",
    "vis1 = sns.distplot(X_train_4['pregnancies glucose'],bins=10, color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2),ax= ax[0][0])\n",
    "vis2 = sns.distplot(X_train_4['pregnancies insulin'], bins =10, color ='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[0][1])\n",
    "vis3 = sns.distplot(X_train_4['glucose^2'],bins=10, color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[0][2])\n",
    "vis4 = sns.distplot(X_train_4[ 'glucose bloodpressure'],bins=10,color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[1][0])\n",
    "vis5 = sns.distplot(X_train_4['glucose insulin'],bins=10,color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[1][1])\n",
    "vis6 = sns.distplot(X_train_4['glucose bmi'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[1][2])\n",
    "vis7 = sns.distplot(X_train_4['bloodpressure^2'],bins=10, color='teal',hist_kws=dict(edgecolor=\"k\", linewidth=2), ax=ax[2][0])\n",
    "vis8 = sns.distplot(X_train_4['skinthickness^2'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[2][1])\n",
    "vis9 = sns.distplot(X_train_4['skinthickness insulin'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[2][2])\n",
    "vis10 = sns.distplot(X_train_4['insulin^2'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[3][0])\n",
    "vis11 = sns.distplot(X_train_4['insulin bmi'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[3][1])\n",
    "vis12 = sns.distplot(X_train_4['insulin^2'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[3][2])\n",
    "vis13 = sns.distplot(X_train_4['insulin age'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[4][0])\n",
    "vis14 = sns.distplot(X_train_4['bmi age'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[4][1])\n",
    "vis15 = sns.distplot(X_train_4['age^2'],bins=10,color='teal', hist_kws=dict(edgecolor=\"k\", linewidth=2),ax=ax[4][2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model 6 : >0 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_5_scaled, ytrain4)\n",
    "y_train_5_pred = logreg.predict(X_train_5_scaled)\n",
    "print('TRAINING F1: ', metrics.f1_score(ytrain4, y_train_5_pred))\n",
    "print(confusion_matrix(ytrain4, y_train_4_pred))\n",
    "\n",
    "y_test_5_pred = logreg.predict(X_test_5_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, y_test_5_pred))\n",
    "print(confusion_matrix(ytest4, y_test_5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THESE :  X_train_5_scaled, ytrain4, X_test_5_scaled, ytest4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(X_train_5_scaled.shape)\n",
    "print(X_test_5_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with xtrain and ytrain values\n",
    "resampling = X_train_5_scaled.copy()\n",
    "resampling['diabetes']= ytrain4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#split the data on the binary value of the outcomes\n",
    "no_diabetes = resampling[resampling['diabetes']==0]\n",
    "diabetes = resampling[resampling['diabetes']==1]\n",
    "print('no diabetes count: '+ str(len(no_diabetes)))\n",
    "print('diabetes count: '+ str(len(diabetes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample (resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample the imbalanced data, there are more observations with zeros\n",
    "no_d_downsampled = resample(no_diabetes,\n",
    "                                replace = False, \n",
    "                                n_samples = len(diabetes), \n",
    "                                random_state = 34) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the downsampled data (zeros) with the outcome data that was split before downsampling (ones)\n",
    "downsampled_train5 = pd.concat([no_d_downsampled, diabetes])\n",
    "downsampled_train5['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return to the xtrain and ytrain format\n",
    "X_train5_downsampled = downsampled_train5.drop('diabetes', axis=1)\n",
    "y_train5_downsampled = downsampled_train5['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train5_downsampled, y_train5_downsampled)\n",
    "y_train_pred_ds1 = logreg.predict(X_train5_downsampled)\n",
    "print('TRAINING F1: ', metrics.f1_score(y_train5_downsampled, y_train_pred_ds1))\n",
    "print(confusion_matrix(y_train5_downsampled, y_train_pred_ds1))\n",
    "\n",
    "y_test_pred_ds1 = logreg.predict(X_test_5_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, y_test_pred_ds1))\n",
    "print(confusion_matrix(ytest4, y_test_pred_ds1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample(TOMEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks()\n",
    "X_tl_train, y_tl_train = tl.fit_sample(X_train_5_scaled, ytrain4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_tl_train, y_tl_train)\n",
    "y_train_pred_tl1 = logreg.predict(X_tl_train)\n",
    "print('TRAINING F1: ', metrics.f1_score(y_tl_train, y_train_pred_tl1))\n",
    "print(confusion_matrix(y_tl_train, y_train_pred_tl1))\n",
    "\n",
    "y_test_pred_tl1 = logreg.predict(X_test_5_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, y_test_pred_tl1))\n",
    "print(confusion_matrix(ytest4, y_test_pred_ds1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample (resampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the split from the downsampling effort above\n",
    "\n",
    "d_train_upsampled = resample(diabetes,\n",
    "                          replace=True, \n",
    "                          n_samples=len(no_diabetes),\n",
    "                          random_state=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_train5 = pd.concat([d_train_upsampled, no_diabetes])\n",
    "upsampled_train5['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train5_upsampled = upsampled_train5.drop('diabetes', axis=1)\n",
    "y_train5_upsampled = upsampled_train5['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train5_upsampled, y_train5_upsampled)\n",
    "y_train_pred_up1 = logreg.predict(X_train5_upsampled)\n",
    "print('TRAINING F1: ', metrics.f1_score(y_train5_upsampled, y_train_pred_up1))\n",
    "print(confusion_matrix(y_train5_upsampled, y_train_pred_up1))\n",
    "\n",
    "y_test_pred_up1 = logreg.predict(X_test_5_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, y_test_pred_up1))\n",
    "print(confusion_matrix(ytest4, y_test_pred_up1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=34, ratio=1.0)\n",
    "X_train_sm, y_train_sm = sm.fit_sample(X_train_5_scaled, ytrain4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_sm, y_train_sm)\n",
    "y_train_pred_sm1 = logreg.predict(X_train_sm)\n",
    "print('TRAINING F1: ', metrics.f1_score(y_train_sm, y_train_pred_sm1))\n",
    "print(confusion_matrix(y_train_sm, y_train_pred_sm1))\n",
    "\n",
    "y_test_pred_sm1 = logreg.predict(X_test_5_scaled)\n",
    "print('TESTING F1: ', metrics.f1_score(ytest4, y_test_pred_sm1))\n",
    "print(confusion_matrix(ytest4, y_test_pred_sm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train5_downsampled.copy()\n",
    "y_train = y_train5_downsampled.copy()\n",
    "X_test = X_test_5_scaled.copy()\n",
    "y_test = ytest4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k(X_train, y_train, X_test, y_test, min_k=1, max_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_error_rate(X_train, y_train, X_test, y_test):\n",
    "    error_rate = []\n",
    "    for i in range(1,60):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred_i = knn.predict(X_test)\n",
    "        error_rate.append(np.mean(pred_i!=y_test))\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = knn_error_rate(X_train, y_train, X_test, y_test)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(range(1,60), error_rate, color='teal',linestyle='--', marker='o', markerfacecolor ='tomato', markersize=10)\n",
    "plt.title('ERROR RATE VS K')\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=23)\n",
    "knn.fit(X_train, y_train)\n",
    "pred_k = knn.predict(X_test)\n",
    "print(\"F1_score:\",metrics.f1_score(y_test, pred_k))\n",
    "print(confusion_matrix(y_test, pred_k))\n",
    "print('')\n",
    "print('')\n",
    "print(classification_report(y_test, pred_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCH \n",
    "parameters={'criterion': ['gini','entropy'], \n",
    "            'min_samples_leaf' : range(5,200,15),\n",
    "            'max_depth': range(2,20,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree=DecisionTreeClassifier(random_state=34)\n",
    "grid_tree=GridSearchCV(clf_tree, parameters, cv=5, scoring='f1')\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_t = grid_tree.best_estimator_.predict(X_test)\n",
    "print(\"F1_score:\",metrics.f1_score(y_test, y_pred_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeClassifier(criterion= 'gini', max_depth= 2, min_samples_leaf= 110)\n",
    "d_tree.fit(X_train, y_train)\n",
    "d_pred = d_tree.predict(X_test)\n",
    "print(\"F1_score:\",metrics.f1_score(y_test, d_pred))\n",
    "print(confusion_matrix(y_test, d_pred))\n",
    "print('/n')\n",
    "print(classification_report(y_test, d_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols= X_train.columns\n",
    "dot_data = StringIO()\n",
    "export_graphviz(d_tree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols, class_names=['0','1'])\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_param_grid = {\n",
    "    'n_estimators': [10, 100, 300, 400],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 10, 15],\n",
    "    'min_samples_split': [10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid_search = GridSearchCV(rfc, rfc_param_grid, cv= 10)\n",
    "rfc_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Testing Accuracy: {:.4}%\".format(rfc_grid_search.best_score_ * 100))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(rfc_grid_search.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_1 = RandomForestClassifier(criterion= 'entropy', max_depth= 15, min_samples_leaf= 1, min_samples_split= 10, n_estimators= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc_1.fit(X_train, y_train)\n",
    "rfc_1_pred = rfc_1.predict(X_test)\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, rfc_1_pred))\n",
    "print('Test F1 score: ', f1_score(y_test, rfc_1_pred))\n",
    "print(classification_report(y_test,rfc_1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg1 = xgb.XGBClassifier(max_depth=3)\n",
    "xg1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_preds = xg1.predict(X_train)\n",
    "preds = xg1.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "test0_f1 = f1_score(y_test, preds)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': .01, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = optimized_GBM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = optimized_GBM.predict(X_train)\n",
    "val_preds = optimized_GBM.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "test1_f1 = f1_score(y_test, val_preds)\n",
    "test1_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the knn model \n",
    " \n",
    "model_pickle_path = 'knn.pkl'\n",
    "\n",
    "# Create an variable to pickle and open it in write mode\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(knn, model_pickle)\n",
    "model_pickle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
